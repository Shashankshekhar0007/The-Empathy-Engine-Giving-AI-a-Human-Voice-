ğŸ§ The Empathy Engine â€” Emotion-Aware AI Voice Synthesis

    An AI-powered service that transforms text into expressive human-like speech by dynamically modulating voice characteristics based on detected emotional intent.

ğŸš€ Features

    ğŸ§  Transformer-based emotion detection
    ğŸ­ Emotion-aware voice modulation
    ğŸ“ˆ Intensity-scaled expressiveness
    ğŸŒ Flask web interface
    ğŸ§ High-quality MP3 output

------------------------------------------------------------------------------------------------

Design Choices & Emotion-to-Voice Mapping Logic

      Emotion Detection

          * Implemented using a transformer-based classifier from Hugging Face.

          * The model predicts emotion labels with confidence scores.

          * The highest-confidence label is selected as the dominant emotional state.

      Emotion Categories

            Internal model outputs (joy, anger, sadness, fear, surprise, etc.) are mapped into three core synthesis categories:

           * Happy (joy, surprise)

           * Frustrated (anger, sadness, fear, disgust)

           * Neutral (fallback state)

      Intensity Scaling

            * The modelâ€™s confidence score (0â€“1) is treated as emotional intensity.

            * Higher intensity results in stronger modulation of voice parameters.

      Voice Modulation Strategy

              Emotion	             Stability	          Style	                Effect
-----------------------------------------------------------------------------------------------                          |                |                                   |
              Happy	Lower|	       Higher |        Energetic                  | bright
              Frustrated |	       Higher |	       Lower	Controlled          | tense
              Neutral	   |         Medium |	       Medium	Balanced            | natural

      This mapping ensures:

             * Clear audible contrast between emotional states

             * Dynamic expressiveness

             * Human-like prosodic variation

 -----------------------------------------------------------------------------------------------

 System Architecture

    User Text (Web UI)
          â†“
    Transformer Emotion Classifier
          â†“
    Emotion + Intensity Scaling
          â†“
    Voice Parameter Mapping
          â†“
    Expressive TTS Engine
          â†“
    Playable MP3 Output

------------------------------------------------------------------------------------------------

ğŸ› ï¸ Tech Stack

    Layer            |     Technology
  ---------------------------------------------
    Language	       |     Python
    Emotion Analysis |     Hugging Face Transformers (Detects emotional intent from text)
    TTS	             |     ElevenLabs API            (Generates expressive human-like speech)
    Web Interface	   |     Flask                     (Serves the web interface)
    NLP	             |     NLTK                       (Splits text into sentences for                                               fine-grained emotional modulation)

------------------------------------------------------------------------------------------------

ğŸ“‚ Project Structure

    empathy-engine/
    â”œâ”€â”€ app.py
    â”œâ”€â”€ web.py
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ index.html
    â”œâ”€â”€ static/
    â”‚   â””â”€â”€ output.mp3
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ .env

------------------------------------------------------------------------------------------------

âš™ï¸ Setup Instructions

    1ï¸âƒ£ Install dependencies
    
        pip install -r requirements.txt

    2ï¸âƒ£ Configure API key

        Create a .env file:
        ELEVENLABS_API_KEY=your_api_key_here

    3ï¸âƒ£ Run the app
        python web.py

ğŸŒ Open in browser

       http://127.0.0.1:5000

-----------------------------------------END OF DOCUMENT----------------------------------------